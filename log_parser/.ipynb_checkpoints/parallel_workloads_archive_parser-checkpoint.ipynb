{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel workloads archive parser\n",
    "\n",
    "Authors of this archive wrote article where explained all problems they faced -> http://www.cs.huji.ac.il/~feit/papers/PWA14JPDC.pdf\n",
    "\n",
    "Authors book about Workload Modeling -> http://www.cs.huji.ac.il/~feit/wlmod/wlmod.pdf\n",
    "\n",
    "Parallel workloads archive link -> http://www.cs.huji.ac.il/labs/parallel/workload/index.html\n",
    "\n",
    "Logs Format -> http://www.cs.huji.ac.il/labs/parallel/workload/swf.html\n",
    "\n",
    "Logs -> http://www.cs.huji.ac.il/labs/parallel/workload/logs.html\n",
    "\n",
    "Log Parser on Perl -> http://www.cs.huji.ac.il/labs/parallel/workload/parse_swf.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard workload format\n",
    "- **Job Number** -- a counter field, starting from 1.\n",
    "\n",
    "- **Submit Time** -- in seconds. The earliest time the log refers to is zero, and is usually the submittal time of the first job. The lines in the log are sorted by ascending submittal times. It makes sense for jobs to also be numbered in this order.\n",
    "\n",
    "- **Wait Time** -- in seconds. The difference between the job's submit time and the time at which it actually began to run. Naturally, this is only relevant to real logs, not to models.\n",
    "\n",
    "- **Run Time** -- in seconds. The wall clock time the job was running (end time minus start time). We decided to use \"wait time\" and \"run time\" instead of the equivalent \"start time\" and \"end time\" because they are directly attributable to the scheduler and application, and are more suitable for models where only the run time is relevant. <font color='red'> Note that when values are rounded to an integral number of seconds (as often happens in logs) a run time of 0 is possible and means the job ran for less than 0.5 seconds. On the other hand it is permissable to use floating point values for time fields. </font>\n",
    "\n",
    "- **Number of Allocated Processors** -- an integer. In most cases this is also the number of processors the job uses; if the job does not use all of them, we typically don't know about it.\n",
    "\n",
    "- **Average CPU Time Used** -- both user and system, in seconds. This is the average over all processors of the CPU time used, and may therefore be smaller than the wall clock runtime. If a log contains the total CPU time used by all the processors, it is divided by the number of allocated processors to derive the average.\n",
    "\n",
    "- **Used Memory** -- in kilobytes. This is again the average per processor.\n",
    "\n",
    "- **Requested Number of Processors**.\n",
    "\n",
    "- **Requested Time** -- This can be either runtime (measured in wallclock seconds), or average CPU time per processor (also in seconds) -- the exact meaning is determined by a header comment. In many logs this field is used for the user runtime estimate (or upper bound) used in backfilling. If a log contains a request for total CPU time, it is divided by the number of requested processors.\n",
    "\n",
    "- **Requested Memory (again kilobytes per processor).**\n",
    "\n",
    "- **Status** 1 if the job was completed, 0 if it failed, and 5 if cancelled. If information about chekcpointing or swapping is included, other values are also possible. See usage note -> (http://www.cs.huji.ac.il/labs/parallel/workload/swf.html). This field is meaningless for models, so would be -1.\n",
    "    - The main usage of the status field is to note the job's status. This isn't as straightforward as it sounds. \n",
    "    - The simple case is jobs that complete normally, and have status 1.\n",
    "    - The harder case is jobs that don't complete normally. This can happen for several reasons:\n",
    "        - The job failed (e.g. segmentation fault). This is given status 0.\n",
    "        - The job was cancelled by the user (like ^C in Unix). This is given status 5. Note that cancelled jobs may have positive runtimes and processors if cancelled after they started to run, or 0 or -1 if cancelled while waiting in the queue.\n",
    "        - The job was killed by the system (e.g. because it exceeded its requested run time). This may be given different status values in different logs; it will typically be 0 or 5, but might also be 1.\n",
    "        \n",
    "        Note also that the distinction between failure / cancellation / killing is not necessarily accurate, as the distinction typically does not appear in the original logs. If a log contains information about checkpoints and swapping out of jobs, a job can have multiple lines in the log. In fact, we propose that the job information appear twice. First, there will be one line that summarizes the whole job: its submit time is the submit time of the job, its runtime is the sum of all partial runtimes, and its code is 0 or 1 according to the completion status of the whole job. In addition, there will be separate lines for each instance of partial execution between being swapped out. All these lines have the same job ID and appear consecutively in the log. Only the first has a submit time; the rest only have a wait time since the previous burst. The completed code for all these lines is 2, meaning \"to be continued\"; the completion code for the last such line is 3 or 4, corresponding to completion or being killed. It should be noted that such details are only useful for studying the behavior of the logged system, and are not a feature of the workload. Such studies should ignore lines with completion codes of 0 and 1, and only use lines with 2, 3, and 4. <font color=\"red\">For workload studies, only the single-line summary of the job should be used, as identified by a code of 0 or 1. </font>\n",
    "\n",
    "- **User ID** -- a natural number, between one and the number of different users.\n",
    "\n",
    "- **Group ID** -- a natural number, between one and the number of different groups. Some systems control resource usage by groups rather than by individual users.\n",
    "\n",
    "- **Executable (Application) Number** -- a natural number, between one and the number of different applications appearing in the workload. In some logs, this might represent a script file used to run jobs rather than the executable directly; this should be noted in a header comment.\n",
    "\n",
    "- **Queue Number** -- a natural number, between one and the number of different queues in the system. The nature of the system's queues should be explained in a header comment. This field is where batch and interactive jobs should be differentiated: we suggest the convention of denoting interactive jobs by 0.\n",
    "\n",
    "- **Partition Number** -- a natural number, between one and the number of different partitions in the systems. The nature of the system's partitions should be explained in a header comment. For example, it is possible to use partition numbers to identify which machine in a cluster was used.\n",
    "\n",
    "- **Preceding Job Number** -- this is the number of a previous job in the workload, such that the current job can only start after the termination of this preceding job. Together with the next field, this allows the workload to include feedback as described below.\n",
    "\n",
    "- **Think Time from Preceding Job** -- this is the number of seconds that should elapse between the termination of the preceding job and the submittal of this one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header Comments\n",
    "- **Version**: Version number of the standard format the file uses. The format described here is version 2.\n",
    "- **Computer**: Brand and model of computer\n",
    "- **Installation**: Location of installation and machine name\n",
    "- **Acknowledge**: Name of person(s) to acknowledge for creating/collecting the workload.\n",
    "- **Information**: Web site or email that contain more information about the workload or installation.\n",
    "- **Conversion**: Name and email of whoever converted the log to the standard format.\n",
    "- **MaxJobs**: Integer, total number of jobs in this workload file.\n",
    "- **MaxRecords**: Integer, total number of records in this workload file. If no checkpointing/swapping information is included, there is one record per job, and this is equal to MaxJobs. But with chekpointing/swapping there may be multiple records per job.\n",
    "- **Preemption**: Enumerated, with four possible values. 'No' means that jobs run to completion, and are represented by a single line in the file. 'Yes' means that the execution of a job may be split into several parts, and each is represented by a separate line. 'Double' means that jobs may be split, and their information appears twice in the file: once as a one-line summary, and again as a sequence of lines representing the parts, as suggested above. 'TS' means time slicing is used, but no details are available.\n",
    "- **UnixStartTime**: When the log starts, in Unix time (seconds since the epoch)\n",
    "- **TimeZone**: DEPRECATED and replaced by TimeZoneString.\n",
    "- A value to add to times given as seconds since the epoch. The sum can then be fed into gmtime (Greenwich time function) to get the correct date and hour of the day. The default is 0, and then gmtime can be used directly. - Note: do not use localtime, as then the results will depend on the difference between your time zone and the installation time zone.\n",
    "- **TimeZoneString**: Replaces the buggy and now deprecated TimeZone. TimeZoneString is a standard UNIX string indicating the time zone in which the log was generated; this is actually the name of a zoneinfo file, e.g. \"Europe/Paris\". All times within the SWF file are in this time zone. For more details see the usage note below.\n",
    "- **StartTime**: When the log starts, in human readable form, in this standard format: Tue Feb 21 18:44:15 IST 2006 (as printed by the UNIX 'date' utility).\n",
    "- **EndTime**: When the log ends (the last termination), formatted like StartTime.\n",
    "- **MaxNodes**: Integer, number of nodes in the computer. List the number of nodes in different partitions in parentheses if applicable.\n",
    "- **MaxProcs**: Integer, number of processors in the computer. This is different from MaxNodes if each node is an SMP. List the number of processors in different partitions in parentheses if applicable.\n",
    "- **MaxRuntime**: Integer, in seconds. This is the maximum that the system allowed, and may be larger than any specific job's runtime in the workload.\n",
    "- **MaxMemory**: Integer, in kilobytes. Again, this is the maximum the system allowed.\n",
    "- **AllowOveruse**: Boolean. 'Yes' if a job may use more than it requested for any resource, 'No' if it can't.\n",
    "- **MaxQueues**: Integer, number of queues used.\n",
    "- **Queues**: A verbal description of the system's queues. Should explain the queue number field (if it has known values). As a minimum it should be explained how to tell between a batch and interactive job.\n",
    "- **Queue**: A description of a single queue in the following format: queue-number queue-name (optional-details). This should be repeated for all the queues.\n",
    "- **MaxPartitions**: Integer, number of partitions used.\n",
    "- **Partitions**: A verbal description of the system's partitions, to explain the partition number field. For example, partitions can be distinct parallel machines in a cluster, or sets of nodes with different attributes (memory configuration, number of CPUs, special attached devices), especially if this is known to the scheduler.\n",
    "- **Partition**: Description of a single partition.\n",
    "- **Note**: There may be several notes, describing special features of the log. For example, The runtime is until the last node was freed; jobs may have freed some of their nodes earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print names of all available logs\n",
    "# TODO\n",
    "\n",
    "import os\n",
    "\n",
    "LOGS_DIR=\"./logs\"\n",
    "LOGS = [\n",
    "    \"CIEMAT-Euler-2008-1.swf\"\n",
    "]\n",
    "\n",
    "\n",
    "class Job:\n",
    "    def __init__(self, description):\n",
    "        params = description.split()\n",
    "        \n",
    "        #  0 - Job Number\n",
    "        self.id = params[0]\n",
    "        \n",
    "        #  1 - Submit Time\n",
    "        self.sub = params[1]\n",
    "\n",
    "        #  2 - Wait Time\n",
    "        self.wait = params[2]\n",
    "        \n",
    "        #  3 - Run Time\n",
    "        self.t = params[3]\n",
    "        \n",
    "        #  4 - Number of Processors\n",
    "        self.p = params[4]\n",
    "        \n",
    "        #  5 - Average CPU Time Used\n",
    "        self.cpu = params[5]\n",
    "        \n",
    "        #  6 - Used Memory\n",
    "        self.mem = params[6]\n",
    "        \n",
    "        #  7 - Requested Number of Processors\n",
    "        self.preq = params[7]\n",
    "        \n",
    "        #  8 - Requested Time\n",
    "        self.treq = params[8]\n",
    "        \n",
    "        #  9 - Requested Memory\n",
    "        self.mreq = params[9]\n",
    "        \n",
    "        # 10 - status (1=completed, 0=killed)\n",
    "        self.status = params[10]\n",
    "        \n",
    "        # 11 - User ID\n",
    "        self.u = params[11]\n",
    "        \n",
    "        # 12 - Group ID\n",
    "        self.gr = params[12]\n",
    "        \n",
    "        # 13 - Executable (Application) Number\n",
    "        self.app = params[13]\n",
    "        \n",
    "        # 14 - Queue Number\n",
    "        self.q = params[14]\n",
    "        \n",
    "        # 15 - Partition Number\n",
    "        self.part = params[15]\n",
    "        \n",
    "        # 16 - Preceding Job Number\n",
    "        self.prec = params[16]\n",
    "        \n",
    "        # 17 - Think Time from Preceding Job\n",
    "        self.think = params[17]\n",
    "\n",
    "\n",
    "class LogFile:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        \n",
    "        self.cnt_fmt  = 0\n",
    "        self.cnt_t0   = 0\n",
    "        self.cnt_p0   = 0\n",
    "        self.cnt_stat = 0\n",
    "        self.cnt_bad  = 0\n",
    "        \n",
    "        self.start = 0\n",
    "        self.jobs  = 0\n",
    "        self.procs = 0\n",
    "        self.nodes = 0\n",
    "        \n",
    "        jobs = []\n",
    "\n",
    "    def read(self):\n",
    "        # TODO\n",
    "        # check file existence\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detail information about specific logs\n",
    "# TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
